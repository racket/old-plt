variable references: there are three kinds of variable references:
1) bound variable refs
2) unit-bound variable refs
3) top-level variable refs

You might be forgiven for some confusion: these three appear to overlap 
heavily.  Here are more accurate defintions for each one:

unit-bound variable references are those which occur as the left-hand sides of 
top-level definitions within a unit.

bound variable references are those which occur within the scope of a 
lambda, case-lambda, let, let*, letrec, or other form which introduces a 
limited lexical scope.  This includes `local', but not the unit-bound 
variables mentioned above.

top-level references are the rest of the references.

One difference between top-level and bound varrefs are the way that they 
are handled at runtime.  Top-level varrefs are looked up in a table; if 
they are not found in this table, a runtime error is signalled.  Note that 
this lookup occurs only when the varref is evaluated, not when it is first 
`encountered' (e.g., in the body of a closure). One reason that this 
mechanism is necessary is that a Scheme REPL permits top-level references 
to variables that have not yet been defined.

Bound varrefs have a known lexical binding location, and they can be looked 
up directly, rather than going through the indirection of checking a table.  
These variables may be introduced by forms like `letrec' or `local', and 
they may furthermore be used before their binding definition has been 
evaluated.  In this case, they have the `<undefined>' value.  In most 
language levels, a reference to a variable which contains the `<undefined>' 
value is an error.  In such a language level, any variable which may have 
this value must be checked on every evaluated reference.

So here's the problem: unit-bound varrefs are similar to those inside a 
`local'.  Syntactically, their bindings are introduced by `define', and their 
scope extends in both directions. Semantically they are similar to 
bound variables, in that the interpreter can lexically fix the binding of 
the variable.  In both of these regards they are similar to the bindings 
in a `local'.  However, zodiac does not parse them like those in a 
`local'.  Rather, it parses them as `top-level-varref's.  Why? I forget, 
and I'm about to ask Matthew yet again.  Then I'll record the answer here.

Now things get a bit more complicated.  Top-level varrefs never need to be 
checked for the '<undefined>' value; before they are bound, they have no 
runtime lookup location at all.  Bound varrefs and unit varrefs, on the 
other hand, may contain the `<undefined>' value.  In particular, those 
bound by letrec, local, and units may contain this value.  Others, like 
those bound by lambda, let, and let*, will not.  For the first and third 
categories, we do not need to check for the undefined value at runtime.  
Only when we are looking at a bound or unit varref which may contain the 
`<undefined>' value do we need to insert a runtime check.

*******

Another topic entirely is that of sharing.  When a break occurs, the 
stepper reconstructs the state of memory. However, two closures may refer 
to the same binding. For instance,

(define-values (setter getter)
  (let ([a '*undefined*])
    (values
     (lambda (x) (set! a x))
     (lambda () a))))

If each closure is linked to a record of the form (lambda () 
values-of-free-vars), there's no way to tell whether the first and second 
closure refer to the same binding of a or not.  So in this case, we must 
devise some other technique to detect sharing.  A simple one suggested by 
Matthew is to store mutators in the closure record; then, sharing can be 
detected by the old bang-one-and-see-if-the-other-changes technique.

*********

A note about source locations: I'm using the "start" locations of sexps 
(assigned by Zodiac) to uniquely identify those expressions: I don't 
believe there are any instances where two expressions share a start 
location.

Later: this is now obsolete: I'm just storing the parsed zodiac 
expressions.  Forget all of this source correlation crap. Zodiac does it 
for me.

*********

Robby has a good point: Matthew's technique for detecting gaps in the 
continuation-mark chain (look for applications whose arguments are fully 
evaluated but are still on the list of current marks) depends on the 
assumption that every "jump site" has the jump as its tail action.  In 
other words, what about things like "invoke-unit/open", which jumps to some
code, evaluates it, >then comes back and binds unit values in the 
environment<.  In this case, the "invoke-unit/open" continuation will not 
be handed directly to the evaluation of the unit, because work remains to 
be done after the evaluation of the unit's definitions.  Therefore, it will 
be impossible to tell when un-annotated code is appearing on the stack in 
uses of "invoke-unit/open."   Problem.

*********

So what the heck does a mark contain for the stepper? it looks like this:

(lambda () (list <source-expr> <var-list>))

with 

var-list = (list-of var)

and

var = (list <val> z:varref)

*********

Let me say a few words here about the overall structure of the 
annotator/stepper combination. We have a choice when rebuilding the source: 
we can follow the source itself, or we can follow the parsed expression 
emitted by zodiac.  If our task is simply to spit out source code, then 
it's clear that we should simply follow the source.  However, we need to 
replace certain variables with the values of their bindings (in 
particular, lambda-bound ones). Well, in beginner mode anyway...

*******


So, here's the next macro we need to handle: define-struct.


*********

Don't forget a test like

(cond [blah]
      [else cond [blah] [blah]])
	  
	  
**********

Okay, I'm a complete moron.  In particular, I threw out all of the source 
correlation code a week ago because I somehow convinced myself that the 
parsed expressions retained references to the read expressions.  That's 
not true; all that's kept is a "location" structure, which records the file 
and offset and all that jazz.  

So I tried to fix that by inserting these source expressions into the 
marks, along with the parsed expressions.  This doesn't work because I 
need to find the read expressions for expressions that don't get marks... 
or do I?  Yes, I do.  In particular, to unparse (define a 3), I need to see 
the read expression to know that it wasn't really (define-values (a) 
(values 3)).

Maybe I can add a field to zodiac structures a la maybe-undefined?

************

That worked great!

************

Man, there's a lot of shared code in here. 

************

Okay, back to the drawing board on a lot of things.

1) Matthias and Robby are of the opinion that the break for an expression 
should be triggered only when that expression becomes the redex.  For 
example, the breakpoint for an if expression is triggered _after_ the test 
expression is evaluated.

2) I've realized that I need a more general approach in the annotater to 
handle binding constructs other than lambda.  In particular, the new 
scheme handles top-level variables differently than lexically bound ones.  
In particular, the mark for an expression contains the value of a 
top-level variable if (1) the variable occurs free in the expression, and 
(2) the expression is on the spine of the current procedure or definition.
Lexically bound variables are placed in the mark if (1) they occur free in 
the expression, and (2) they are in tail position relative to the innermost 
binding expression for the variable.

*** Wait, no.  This is crap, because the bodies of lambdas need to store 
all free variables, regardless of whether they're lexically tail w.r.t. 
the binding occurrence. Maybe it really would just be easier to do this in 
two passes.  How would this work?  One pass would attach the free variables 
to each expression.  Then, the variables you must store in the mark for an 
expression are those which (1) occur free and (2) are not contained in 
some lexically enclosing expression. I guess we can use the 
register-client ability of zodiac for this... 

We're helped out in the lexical variables by the fact that zodiac renames 
all lexically bound variables, so no two bindings have the same name. Of 
course, that's not the case for the special variables inserted by the 
annotator.  Most of these ... well, no, all of these will have to appear 
in marks now.  The question is whether they'll ever fight with each other. 
In the case of applications, I'm okay, because the only expressions which 
appear in tail ... wait, wait, the only problem that I could have here 
arises when top-level variables have the same names as lexically bound 
ones, and since all of the special ones are lexically bound, this is fine. 


************

I'm taking these comments out of the program file.  They just clutter 
things up.

           ; make-debug-info takes a list of variables and an expression and
           ; creates a thunk closed over the expression and (if bindings-needed is true) 
           ; the following information for each variable in kept-vars:
           ; 1) the name of the variable (could actually be inferred)
           ; 2) the value of the variable
           ; 3) a mutator for the variable, if it appears in mutated-vars.
           ; (The reason for the third of these is actually that it can be used
           ;  in the stepper to determine which bindings refer to the same location,
           ;  as per Matthew's suggestion.)
           ; 
           ; as an optimization:
           ; note that the mutators are needed only for the bindings which appear in
           ; closures; no location ambiguity can occur in the 'currently-live' bindings,
           ; since at most one location can exist for any given stack binding.  That is,
           ; using the source, I can tell whether variables referenced directly in the
           ; continuation chain refer to the same location.
           
           ; okay, things have changed a bit.  For this iteration, I'm simply not going to 
           ; store mutators.  later, I'll add them in.

		  
************

Okay, I'm back to the one-pass scheme, and here's how it's going to work.  
Top-level variables are handled differently from lexically bound ones.  
Annotate/inner takes an expression to annotate, and a list of variables whose 
bindings the current expression is in tail position to.  This list may 
optionally also hold the symbol 'all, which indicates that all variables 
which occur free should be placed in the mark.


***********

Regarding the question: what the heck is this lexically-bound-vars argument 
to annotate-source-expr?  The answer is that if we're displaying a lambda, 
we do not have values for the variables whose bindings are the arguments 
to the lambda.  For instance, suppose we have:

(define my-top-level 13)

(define my-closure
  (lambda (x) (x top-level)))

When we're displaying my-closure, we better not try to find a value for x 
when reconstructing the body, as there isn't one.

*************

This may come back to haunt me: the temporary variables I'm introducing for 
applications and 'if's are funny: they have no bindings.  They have no 
orig-name's.  They _must_ be expanded, always. This may be a problem when 
I stop displaying the values of lambda-bound variables.

***************

currently on the stack:

yank all of that 'comes-from-blah' crap if read->raw works.

*************

annotater philosophy: don't look at the source; just expand based on the 
parsed expression.  The information you need to reconstruct the 
